Modelle:
Baseline:
1. Zero-shot Probing auf pretrained ROBERTA
2. Für NLI fine-tuned ROBERTA mit Classification Head
Unsere:
3. ROBERTA fine-tuned nur mit Hypotheses
4. Ensemble: hypothesis-only Model freezed + standard ROBERTA fine-tuning mit hypothesis-only model
5. ROBERTA fine-tuning auf MultiNLI mit reduziertem Bias

Tests:
1. Accuracy (F1 + MCC) auf SICK und eSNLI einzeln nach Kategorien
2. Auf Bias überprüfen: Vergleich vom Modell für wichtig erachtete Token mit von Menschen als wichitg erachtete Tokens
Visualisierungen:
- Confusion Matrix (Gentrennt nach Phänomenen)
- Tabellen Interpretability Metriken (siehe ferret)

Bonus: Verlauf der Metriken über das fine-tuning hinweg

Daten:
Training:
- MultiNLI
- optional: SICK (weil wenige Daten)
Test:
- eSNLI für Interpretability, Kategorisiert nach linguistischen Phänomenen
- SICK für Accuracy, weil eSNLI hat Bias ohne Ende
