\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{csquotes}
\usepackage{setspace}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[nolist]{acronym}
\usepackage[T1]{fontenc}
\usepackage{subfig}
\usepackage{placeins}
\usepackage[nolist]{acronym}
\usepackage[style=authoryear]{biblatex}

\onehalfspacing
\setlength{\parindent}{0pt}
\setlength{\parskip}{10pt}

\addbibresource{literature.bib}

\title{Project LIT - Outline}
\author{Niklas Loeser, Erik Imgrund, Andre Trump}
\date{\today}

\begin{document}

\begin{acronym}
    \acro{LM}{Language Model}
    \acro{NLI}{Natural Language Inference}
    \acro{PLM}{Pretrained Language Model}
\end{acronym}

\maketitle

\section{Task Description (Niklas)}
What is NLI?

What is our aim?

What are our hypotheses?

\section{Method (Erik)}
How to probe for NLI?

How to fine-tune for NLI?

How do we detect biased data?

How to mitigate biases?

\section{Models and Data Sets (Erik)}
Which models do we use?

Roberta, aber welche?

Which data sets to use?

- MultiNLI
- SICK
- eSNLI

\section{Experiments (Andre)}
Baseline:
1. Zero-shot Probing auf pretrained ROBERTA
2. Für NLI fine-tuned ROBERTA mit Classification Head
Unsere:
3. ROBERTA fine-tuned nur mit Hypotheses
4. Ensemble: hypothesis-only Model freezed + standard ROBERTA fine-tuning mit hypothesis-only model
5. ROBERTA fine-tuning auf MultiNLI mit reduziertem Bias

Training:
- MultiNLI
- optional: SICK (weil wenige Daten)
Test:
- eSNLI für Interpretability, Kategorisiert nach linguistischen Phänomenen
- SICK für Accuracy, weil eSNLI hat Bias ohne Ende

\section{Analysis (Niklas)}
1. Accuracy (F1 + MCC) auf SICK und eSNLI einzeln nach Kategorien
2. Auf Bias überprüfen: Vergleich vom Modell für wichtig erachtete Token mit von Menschen als wichitg erachtete Tokens
Visualisierungen:
- Confusion Matrix (Gentrennt nach Phänomenen)
- Tabellen Interpretability Metriken (siehe ferret)


\printbibliography

\end{document}