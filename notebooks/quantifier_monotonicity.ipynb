{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b2eb700",
   "metadata": {},
   "source": [
    "# Quantifiers\n",
    "## Quantifier Phrases\n",
    "- characterized by occurrence before the descriptive adjectives in a noun phrase [1]\n",
    "- sometimes qualified by adjectives or relative clauses [2]\n",
    "- determiners like \"every\" are binary quantifiers $Q(A, B)$ which connect A and B to form a sentence \n",
    "\n",
    "## Sentence construction from quantifier phrases\n",
    "- quantifier phrases may in turn combine with predicates [2]\n",
    "\n",
    "\n",
    "1: https://www.merriam-webster.com/dictionary/quantifier\n",
    "2: https://plato.stanford.edu/entries/quantification/\n",
    "3: https://en.wikipedia.org/wiki/List_of_English_determiners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "bc89fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Any, Tuple\n",
    "\n",
    "@dataclass\n",
    "class Quantifier:\n",
    "    name: str\n",
    "    left_rising: bool\n",
    "    right_rising: bool\n",
    "    tags: List[List[str]]\n",
    "\n",
    "        \n",
    "all_quantifiers = [\n",
    "    Quantifier(\"a few\", True, True, [[\"DT\", \"JJ\"]]),\n",
    "    Quantifier(\"a large number of\", True, True, [[\"DT\", \"JJ\", \"NN\", \"IN\"]]),\n",
    "    Quantifier(\"a little\", True, True, [[\"DT\", \"JJ\"]]),\n",
    "    Quantifier(\"a number of\", True, True, [[\"DT\", \"NN\", \"IN\"]]),\n",
    "    Quantifier(\"a small number of\", True, True, [[\"DT\", \"JJ\", \"NN\", \"IN\"]]),\n",
    "    Quantifier(\"all\", False, True, [[\"DT\"]]),\n",
    "    Quantifier(\"any\", False, True, [[\"DT\"]]),\n",
    "    Quantifier(\"enough\", True, True, [[\"DT\"]]),\n",
    "    Quantifier(\"each\", False, True, [[\"DT\"]]),\n",
    "    Quantifier(\"every\", True, True, [[\"DT\"]]),\n",
    "    Quantifier(\"few\", False, False, [[\"DT\"]]),\n",
    "    Quantifier(\"fewer\", False, False, [[\"DT\"]]),\n",
    "    Quantifier(\"less\", False, False, [[\"DT\"], [\"RB\"], [\"IN\"], [\"JJR\"]]), # Also adverb and preposition\n",
    "    Quantifier(\"lots of\", True, True, [[\"RB\", \"IN\"], [\"NNS\", \"IN\"]]), # Idiom: adverb + preposition\n",
    "    Quantifier(\"many\", True, True, [[\"DT\"], [\"JJ\"]]),\n",
    "    Quantifier(\"most\", False, True, [[\"DT\"]]),\n",
    "    Quantifier(\"most of\", False, True, [[\"JJS\", \"IN\"]]),\n",
    "    Quantifier(\"much\", True, True, [[\"DT\"]]),\n",
    "    Quantifier(\"much of\", True, True, [[\"NN\", \"IN\"]]),\n",
    "    Quantifier(\"no\", False, False, [[\"DT\"]]),\n",
    "    Quantifier(\"none of\", False, False, [[\"NN\", \"IN\"]]),\n",
    "    Quantifier(\"not many\", False, False, [[\"RB\", \"JJ\"]]),\n",
    "    Quantifier(\"not much\", False, False, [[\"RB\", \"JJ\"]]),\n",
    "    Quantifier(\"numerous\", True, True, [[\"JJ\"]]), # Adjective\n",
    "    Quantifier(\"plenty of\", True, True, [[\"NN\", \"IN\"]]), # Idiom: Pronoun + preposition\n",
    "    Quantifier(\"several\", True, True, [[\"DT\"], [\"JJ\"]]), # Also pronoun\n",
    "    Quantifier(\"some\", True, True, [[\"DT\"]]),\n",
    "    Quantifier(\"whole\", False, True, [[\"RB\"], [\"JJ\"]]), # Adverb\n",
    "    Quantifier(\"many of\", True, True, [[\"NN\", \"IN\"]]), # Noun + preposition\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1e140490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "from lxml import etree\n",
    "from dataclasses import dataclass\n",
    "CANDC_PATH = \"../scripts/quantifier_monotonicity/candc-1.00\"\n",
    "SED_PATH = \"../scripts/quantifier_monotonicity/tokenizer.sed\"\n",
    "\n",
    "def print_xml(xml: \"XML\"):\n",
    "    print(etree.tostring(xml, pretty_print=True).decode(\"utf-8\"))\n",
    "\n",
    "def parse(sentence: str) -> \"XML\":\n",
    "    sentence = sentence.replace(\"\\\"\", \"\\\\\\\"\")\n",
    "    ps = subprocess.run(\n",
    "        f\"echo \\\"{sentence}\\\" | sed -f {SED_PATH} | {CANDC_PATH}/bin/candc --models {CANDC_PATH}/models/ --candc-printer xml\", \n",
    "        stdout=subprocess.PIPE,\n",
    "        shell=True\n",
    "        )\n",
    "    xml = etree.fromstring(ps.stdout)\n",
    "    return xml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8b6d7d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "@dataclass\n",
    "class QuantifierMatch:\n",
    "    quantifier: Quantifier\n",
    "\n",
    "@dataclass\n",
    "class TokenMatch:\n",
    "    index: int\n",
    "    quantifier: Quantifier\n",
    "        \n",
    "def token_list(xml: \"XML\") -> List[Tuple[str, str]]:\n",
    "    return etree.XPath(\"//lf\")(xml)\n",
    "        \n",
    "\n",
    "def match_token(tokens: List[Tuple[str, str]], quantifier):\n",
    "    \"\"\"\n",
    "    Assume that a specific quantifier only appears once per sentence\n",
    "    \"\"\"\n",
    "    start_index = 0\n",
    "    q_tokens = quantifier.name.split(\" \")\n",
    "    q_token_count = len(q_tokens)\n",
    "    match = None\n",
    "    for index, token in enumerate(tokens):\n",
    "        q_index = index - start_index\n",
    "        if q_tokens[q_index] != token.attrib[\"word\"]:\n",
    "            start_index = index+1\n",
    "            continue\n",
    "        if q_index == q_token_count - 1:\n",
    "            match = TokenMatch(start_index, quantifier)\n",
    "            break\n",
    "    if match is None:\n",
    "        return None\n",
    "    for tags in quantifier.tags:\n",
    "        for index, pair in enumerate(zip(tags, [lf.attrib[\"pos\"] for lf in tokens][match.index:])):\n",
    "            if pair[0] != pair[1]:\n",
    "                break\n",
    "            if index == q_token_count -1:\n",
    "                return match\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_all_ancestors(elem):\n",
    "    ret = []\n",
    "    while elem.getparent() is not None:\n",
    "        ret.append(elem.getparent())\n",
    "        elem = elem.getparent()\n",
    "    return ret\n",
    "\n",
    "\n",
    "def lowest_common_ancestor(elem1, elem2):\n",
    "    elem1a = get_all_ancestors(elem1)\n",
    "    elem2a = get_all_ancestors(elem2)\n",
    "    return next(e1 for e1, e2 in zip(elem1a, elem2a) if e1 == e2)\n",
    "\n",
    "VP_REGEX = r\"^S[[\\]a-z]*[\\\\/]NP$\"\n",
    "NP_REGEX = r\"^NP$\"\n",
    "SOMETHING_REGEX = r\"^\\(S[[\\]a-z]*[\\\\/]NP\\)[\\\\/]\\(S[[\\]a-z]*[\\\\/]NP\\)$\"\n",
    "\n",
    "def is_vp(node):\n",
    "    return re.search(VP_REGEX, node.attrib[\"cat\"]) is not None\n",
    "def is_np(node):\n",
    "    return re.search(NP_REGEX, node.attrib[\"cat\"]) is not None\n",
    "def is_something(node):\n",
    "    return re.search(SOMETHING_REGEX, node.attrib[\"cat\"]) is not None\n",
    "\n",
    "def find_direction(direction, check, element):\n",
    "    element = direction(element)\n",
    "    if element is None:\n",
    "        return None\n",
    "    if check(element):\n",
    "        return element\n",
    "    elif is_something(element):\n",
    "        return find_direction(direction, check, element)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def previous_node(node):\n",
    "    return node.getprevious()\n",
    "\n",
    "def next_node(node):\n",
    "    return node.getnext()\n",
    "    \n",
    "def find_sibling_npvp(element):\n",
    "    if is_np(element):\n",
    "        print(element.tag, element.attrib[\"cat\"])\n",
    "        maybe_vp = find_direction(next_node, is_vp, element)\n",
    "        if maybe_vp is None:\n",
    "            maybe_vp = find_direction(previous_node, is_vp, element)\n",
    "        if maybe_vp is not None:\n",
    "            return (element, maybe_vp)\n",
    "    elif is_vp(element):\n",
    "        print(element.tag, element.attrib[\"cat\"])\n",
    "        maybe_np = find_direction(next_node, is_np, element)\n",
    "        if maybe_np is None:\n",
    "            maybe_np = find_direction(previous_node, is_np, element)\n",
    "        if maybe_np is not None:\n",
    "            return (maybe_np, element)\n",
    "    elif is_something(element):\n",
    "        maybe_np = find_direction(next_node, is_np, element)\n",
    "        if maybe_np is None:\n",
    "            maybe_np = find_direction(previous_node, is_np, element)\n",
    "        maybe_vp = find_direction(next_node, is_vp, element)\n",
    "        if maybe_vp is None:\n",
    "            maybe_vp = find_direction(previous_node, is_vp, element)\n",
    "        if maybe_vp is not None and maybe_np is not None:\n",
    "            return (maybe_np, maybe_vp)\n",
    "    else:\n",
    "        parent = element.getparent()\n",
    "        if parent is None:\n",
    "            return None\n",
    "        else:\n",
    "            return find_sibling_npvp(parent)\n",
    "        \n",
    "        \n",
    "\n",
    "def find_npvp(token_list) -> \"XML\":\n",
    "    \"\"\"Find the first NP rule common ancestor of first and last LF\"\"\"\n",
    "    first = token_list[0]\n",
    "    last = token_list[-1]\n",
    "    common_ancestor = lowest_common_ancestor(first, last)\n",
    "    return find_sibling_npvp(common_ancestor)\n",
    "        \n",
    "    \n",
    "def match_quantifier(xml: \"XML\") -> List[QuantifierMatch]:\n",
    "    tokens = token_list(xml)\n",
    "    token_matches = list(filter(None, [match_token(tokens, quantifier) for quantifier in all_quantifiers]))\n",
    "    matched_tokens = [\n",
    "        tokens[match.index:match.index+len(match.quantifier.tags[0])]\n",
    "        for match in token_matches\n",
    "    ]\n",
    "    npvp = [find_npvp(token_list) for token_list in matched_tokens]\n",
    "    return token_matches, npvp\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a5e38ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/semproj/sem_proj22/proj_05/lit_niklas/venv/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Possible nested set at position 3\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "re.search(VP_REGEX, r\"(S[dcl]\\NP)/NP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "82e2ed66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<candc>\n",
      "<ccg>\n",
      " <rule type=\"ba\" cat=\"NP\">\n",
      "  <rule type=\"lex\" cat=\"NP\">\n",
      "   <lf start=\"0\" span=\"1\" word=\"Jindal\" lemma=\"Jindal\" pos=\"NNP\" chunk=\"I-NP\" entity=\"O\" cat=\"N\"/>\n",
      "  </rule>\n",
      "  <rule type=\"fa\" cat=\"NP\\NP\">\n",
      "   <lf start=\"1\" span=\"1\" word=\":\" lemma=\":\" pos=\"IN\" chunk=\"O\" entity=\"O\" cat=\"(NP\\NP)/S[dcl]\"/>\n",
      "   <rule type=\"ba\" cat=\"S[dcl]\">\n",
      "    <rule type=\"lex\" cat=\"NP\">\n",
      "     <lf start=\"2\" span=\"1\" word=\"GOP\" lemma=\"GOP\" pos=\"NNP\" chunk=\"I-NP\" entity=\"I-ORG\" cat=\"N\"/>\n",
      "    </rule>\n",
      "    <rule type=\"fa\" cat=\"S[dcl]\\NP\">\n",
      "     <lf start=\"3\" span=\"1\" word=\"must\" lemma=\"must\" pos=\"MD\" chunk=\"I-VP\" entity=\"O\" cat=\"(S[dcl]\\NP)/(S[b]\\NP)\"/>\n",
      "     <rule type=\"ba\" cat=\"S[b]\\NP\">\n",
      "      <rule type=\"ba\" cat=\"S[b]\\NP\">\n",
      "       <lf start=\"4\" span=\"1\" word=\"compete\" lemma=\"compete\" pos=\"VB\" chunk=\"I-VP\" entity=\"O\" cat=\"S[b]\\NP\"/>\n",
      "       <rule type=\"fa\" cat=\"(S[X]\\NP)\\(S[X]\\NP)\">\n",
      "        <lf start=\"5\" span=\"1\" word=\"for\" lemma=\"for\" pos=\"IN\" chunk=\"I-PP\" entity=\"O\" cat=\"((S\\NP)\\(S\\NP))/NP\"/>\n",
      "        <rule type=\"fa\" cat=\"NP[nb]\">\n",
      "         <lf start=\"6\" span=\"1\" word=\"every\" lemma=\"every\" pos=\"DT\" chunk=\"I-NP\" entity=\"O\" cat=\"NP[nb]/N\"/>\n",
      "         <lf start=\"7\" span=\"1\" word=\"vote\" lemma=\"vote\" pos=\"NN\" chunk=\"I-NP\" entity=\"O\" cat=\"N\"/>\n",
      "        </rule>\n",
      "       </rule>\n",
      "      </rule>\n",
      "      <rule type=\"conj\" cat=\"(S[b]\\NP)\\(S[b]\\NP)\">\n",
      "       <lf start=\"8\" span=\"1\" word=\",\" lemma=\",\" pos=\",\" chunk=\"O\" entity=\"O\" cat=\",\"/>\n",
      "       <rule type=\"ba\" cat=\"S[b]\\NP\">\n",
      "        <rule type=\"fa\" cat=\"S[b]\\NP\">\n",
      "         <lf start=\"9\" span=\"1\" word=\"reject\" lemma=\"reject\" pos=\"VB\" chunk=\"I-VP\" entity=\"O\" cat=\"(S[b]\\NP)/NP\"/>\n",
      "         <rule type=\"lex\" cat=\"NP\">\n",
      "          <rule type=\"fa\" cat=\"N\">\n",
      "           <lf start=\"10\" span=\"1\" word=\"identity\" lemma=\"identity\" pos=\"NN\" chunk=\"I-NP\" entity=\"O\" cat=\"N/N\"/>\n",
      "           <lf start=\"11\" span=\"1\" word=\"politics\" lemma=\"politics\" pos=\"NNS\" chunk=\"I-NP\" entity=\"O\" cat=\"N\"/>\n",
      "          </rule>\n",
      "         </rule>\n",
      "        </rule>\n",
      "        <rule type=\"conj\" cat=\"(S[b]\\NP)\\(S[b]\\NP)\">\n",
      "         <lf start=\"12\" span=\"1\" word=\",\" lemma=\",\" pos=\",\" chunk=\"O\" entity=\"O\" cat=\",\"/>\n",
      "         <rule type=\"fa\" cat=\"S[b]\\NP\">\n",
      "          <lf start=\"13\" span=\"1\" word=\"be\" lemma=\"be\" pos=\"VB\" chunk=\"I-VP\" entity=\"O\" cat=\"(S[b]\\NP)/(S[adj]\\NP)\"/>\n",
      "          <rule type=\"fa\" cat=\"S[adj]\\NP\">\n",
      "           <lf start=\"14\" span=\"1\" word=\"more\" lemma=\"more\" pos=\"RBR\" chunk=\"I-ADJP\" entity=\"O\" cat=\"(S[adj]\\NP)/(S[adj]\\NP)\"/>\n",
      "           <lf start=\"15\" span=\"1\" word=\"smart\" lemma=\"smart\" pos=\"JJ\" chunk=\"I-ADJP\" entity=\"O\" cat=\"S[adj]\\NP\"/>\n",
      "          </rule>\n",
      "         </rule>\n",
      "        </rule>\n",
      "       </rule>\n",
      "      </rule>\n",
      "     </rule>\n",
      "    </rule>\n",
      "   </rule>\n",
      "  </rule>\n",
      " </rule>\n",
      "</ccg>\n",
      "</candc>\n",
      "\n",
      "rule S[b]\\NP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 7.14362 406 554\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3566182/3352278057.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_quantifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566182/3352278057.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_quantifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "xml = parse(\"Jindal : GOP must compete for every vote , reject identity politics , be more smart\")\n",
    "print_xml(xml)\n",
    "result = match_quantifier(xml)\n",
    "nps = result[1]\n",
    "nps = [(etree.tostring(np), etree.tostring(vp)) for np, vp in nps]\n",
    "result[0], nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7982c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "        \"Bush says most of Congress \\\" acting like a teenager with a new credit card \\\"\", # 0\n",
    "        \"Shaun White is the most successful snowboarder\", # 1\n",
    "        \"O'Neill : no judge on Supreme Court now has legislative background\", # 2\n",
    "        \"three - time winner Boris Becker believes any of the top four players could triumph\", # 3\n",
    "        \"Arun Kundnani : some urge a U.S. government program aimed at extreme Muslim views\", # 4\n",
    "        \"the owner of this estate is no ordinary Lord of the Manor -- it 's Russian tycoon Max\", # 5\n",
    "        \"\\\" this wonderful couple is a danger to no one , \\\" writes Bourdain\", # 6\n",
    "        \"while in prison , Mandela became most significant black leader in South Africa\", # 7\n",
    "        \"new : Winfrey : \\\" we need a president who can bring us all together \\\"\", # 8\n",
    "        \"Brazile : Norquist is the man most responsible for GOP gridlock in Washington\", # 9\n",
    "        \"Earl Jr. believes Tiger has no one to keep him on the right path\", # 10\n",
    "        \"world no. 3 Lee Westwood agrees with the move saying phones are key for business\", # 11\n",
    "        \"there 's no substitute for American leadership in this critical region , he says\", # 12\n",
    "        \"rising tide of Taliban and threat of violence has some residents worried\", # 13\n",
    "        \"Ban : \\\" i can not find any other better suited leader \\\"\", # 14\n",
    "\"the 24 - year - old is one of Australia 's most popular Olympic athletes\", # 15\n",
    "        \"ruling : \\\" Manuel Noriega fails to provide any evidence of harm to his reputation \\\"\", # 16\n",
    "        \"the Bay area and Detroit have the most arrests and child rescues\", # 17\n",
    "        \"no specific threat is indicated against the U.S.\", # 18\n",
    "        \"the U.S. Navy has announced it will no longer communicate in all - caps\", # 19\n",
    "        \"44 million U.S. smoke , and a third of all cancer deaths caused by tobacco use\", # 20\n",
    "        \"Vodafone 's HTC Magic handset will launch in western Europe in the next few months\", # 21\n",
    "        \"moses shown on some Supreme Court friezes ; some founders wrote of Christian principles\", # 22\n",
    "        \"some customers say UPS packages were declared \\\" delivered \\\" but were n't\", # 23\n",
    "        \"Maathai of the West : \\\" nobody has a blueprint and nobody is a know - it - all \\\"\", # 24\n",
    "        \"Antonieta Ledezma is joined by a few dozen protesters in New York 's Times Square\", # 25\n",
    "        \"\\\" i have no doubt i 'll lose , \\\" says California lawyer who filed lawsuit\", # 26\n",
    "        \"Greene : beyond that , it 's American justice carried out for us all ; important to bear witness\", # 27\n",
    "        \"protesters , Israel soldiers clash every friday afternoon in two West Bank villages\", # 28\n",
    "        \"the world no. 1 faces Andy Murray on sunday\", # 29\n",
    "        \"Jindal : GOP must compete for every vote , reject identity politics , be more smart\", # 30\n",
    "        \"Toshiba lost because it lacks retail presence in many key markets , analysts say\", # 31\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c0dea25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 attempt nospan at B=0.075, K=20\n",
      "1 attempt nospan at B=0.03, K=20\n",
      "1 attempt nospan at B=0.01, K=20\n",
      "1 attempt nospan at B=0.005, K=20\n",
      "1 attempt nospan at B=0.001, K=150\n",
      "1 failed no span at B=0.001, K=150\n",
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 2.07944 86 88\n",
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 3.4012 220 233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule NP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 4.57471 405 463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule NP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 4.27667 268 284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule NP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 9.56549 1095 1445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule NP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 7.96901 755 997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule NP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 5.24175 427 532\n",
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 attempt nospan at B=0.075, K=20\n",
      "1 attempt nospan at B=0.03, K=20\n",
      "1 attempt nospan at B=0.01, K=20\n",
      "1 attempt nospan at B=0.005, K=20\n",
      "1 attempt nospan at B=0.001, K=150\n",
      "1 failed no span at B=0.001, K=150\n",
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 6.2106 426 509\n",
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 5.94542 463 543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule NP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 9.18502 1113 1543\n",
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 7.0282 744 924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule NP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 8.74576 733 946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule NP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 attempt nospan at B=0.075, K=20\n",
      "1 attempt nospan at B=0.03, K=20\n",
      "1 attempt nospan at B=0.01, K=20\n",
      "1 attempt nospan at B=0.005, K=20\n",
      "1 attempt nospan at B=0.001, K=150\n",
      "1 failed no span at B=0.001, K=150\n",
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 5.8861 428 467\n",
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 attempt nospan at B=0.075, K=20\n",
      "1 attempt nospan at B=0.03, K=20\n",
      "1 attempt nospan at B=0.01, K=20\n",
      "1 attempt nospan at B=0.005, K=20\n",
      "1 attempt nospan at B=0.001, K=150\n",
      "1 failed no span at B=0.001, K=150\n",
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 4.09434 453 523\n",
      "# this file was generated by the following command(s):\n",
      "#   ../scripts/quantifier_monotonicity/candc-1.00/bin/candc --models ../scripts/quantifier_monotonicity/candc-1.00/models/ --candc-printer xml\n",
      "\n",
      "1 parsed at B=0.075, K=20\n",
      "1 coverage 100%\n",
      "1 stats 3.43399 213 239\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3566182/1348876488.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatch_quantifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566182/1348876488.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmatch_quantifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566182/4234342062.py\u001b[0m in \u001b[0;36mmatch_quantifier\u001b[0;34m(xml)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_matches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     ]\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mnpvp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfind_npvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatched_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtoken_matches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpvp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566182/4234342062.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_matches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     ]\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mnpvp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfind_npvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatched_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtoken_matches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpvp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566182/4234342062.py\u001b[0m in \u001b[0;36mfind_npvp\u001b[0;34m(token_list)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mcommon_ancestor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlowest_common_ancestor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfind_sibling_npvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_ancestor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566182/4234342062.py\u001b[0m in \u001b[0;36mfind_sibling_npvp\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfind_sibling_npvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566182/4234342062.py\u001b[0m in \u001b[0;36mfind_sibling_npvp\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfind_sibling_npvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566182/4234342062.py\u001b[0m in \u001b[0;36mfind_sibling_npvp\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfind_sibling_npvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566182/4234342062.py\u001b[0m in \u001b[0;36mfind_sibling_npvp\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_sibling_npvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrib\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mmaybe_vp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_direction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_vp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3566182/4234342062.py\u001b[0m in \u001b[0;36mis_np\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVP_REGEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrib\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNP_REGEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrib\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_something\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSOMETHING_REGEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrib\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cat\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/lxml/etree.pyx\u001b[0m in \u001b[0;36mlxml.etree._Attrib.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cat'"
     ]
    }
   ],
   "source": [
    "results = [match_quantifier(parse(s)) for s in sentences ]\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "002c625d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [('NP[nb]/N', 'N')],\n",
       " [('NP', 'NP\\\\NP'), ('((S\\\\NP)\\\\(S\\\\NP))/N', 'N')],\n",
       " [('NP[nb]/N', 'N'), ('NP[nb]/N', 'N')],\n",
       " [],\n",
       " [],\n",
       " [('NP[nb]/N', 'N')]]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nps = [b for a,b in results]\n",
    "[[(n.attrib[\"cat\"], v.attrib[\"cat\"]) for n, v in np] for np in nps]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
