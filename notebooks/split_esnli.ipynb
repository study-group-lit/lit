{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "esnli = load_dataset(\"../datasets/esnli.py\")\n",
    "esnli.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_highlighted(record: dict) -> dict:\n",
    "    highlighted_premise_all = set()\n",
    "    highlighted_hypothesis_all = set()\n",
    "    for i in range(1, 4):\n",
    "        highlighted_current_premise = get_words_at_indices(record[\"premise\"], parse_indices(record[f\"premise_highlighted_{i}\"]))\n",
    "        highlighted_premise_all.update(highlighted_current_premise)\n",
    "        record[f\"premise_highlighted_{i}\"] = \",\".join(highlighted_current_premise)\n",
    "        highlighted_current_hypothesis = get_words_at_indices(record[\"hypothesis\"], parse_indices(record[f\"hypothesis_highlighted_{i}\"]))\n",
    "        highlighted_hypothesis_all.update(highlighted_current_hypothesis)\n",
    "        record[f\"hypothesis_highlighted_{i}\"] = \",\".join(highlighted_current_hypothesis)\n",
    "    record[\"highlighted_premise_all\"] = \",\".join(highlighted_premise_all)\n",
    "    record[\"highlighted_hypothesis_all\"] = \",\".join(highlighted_hypothesis_all)\n",
    "    return record\n",
    "\n",
    "def parse_indices(indices: str) -> list[int]:\n",
    "    if indices in [r\"{}\", \"\"]:\n",
    "        return []\n",
    "    return [int(i) for i in indices.split(\",\")]\n",
    "\n",
    "def get_words_at_indices(string: str, indices: list[int]) -> str:\n",
    "    split_string = string.split(\" \")\n",
    "    return filter(lambda word: word != \"\", map(lambda i: re.sub(r\"[.,!?]\", \"\", split_string[i]), indices))\n",
    "\n",
    "splits = [\"train\", \"test\", \"validation\"]\n",
    "for split in splits:\n",
    "    esnli[split] = esnli[split].map(transform_highlighted, num_proc=8)\n",
    "\n",
    "esnli.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word: str) -> set[str]:\n",
    "    synonyms = set()\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return synonyms\n",
    "\n",
    "def get_antonyms(word: str) -> set[str]:\n",
    "    antonyms = set()\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            if lemma.antonyms():\n",
    "                antonyms.add(lemma.antonyms()[0].name())\n",
    "    return antonyms\n",
    "\n",
    "def get_hypernyms(word: str) -> set[str]:\n",
    "    hypernyms = set()\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            if lemma.hypernyms():\n",
    "                hypernyms.add(lemma.hypernyms()[0].name())\n",
    "    return hypernyms\n",
    "\n",
    "def get_hyponyms(word: str) -> set[str]:\n",
    "    hyponyms = set()\n",
    "    for synset in wordnet.synsets(word):\n",
    "        for lemma in synset.lemmas():\n",
    "            if lemma.hyponyms():\n",
    "                hyponyms.add(lemma.hyponyms()[0].name())\n",
    "    return hyponyms\n",
    "\n",
    "simple_relation_functions = {\n",
    "    \"synonym\": get_synonyms,\n",
    "    \"antonym\": get_antonyms,\n",
    "    \"hypernym\": get_hypernyms,\n",
    "    \"hyponym\": get_hyponyms,\n",
    "}\n",
    "\n",
    "def add_simple_relation_column(record: dict, relation: str) -> dict:\n",
    "    important_premise = set(record[\"highlighted_premise_all\"].split(\",\"))\n",
    "    important_hypothesis = set(record[\"highlighted_hypothesis_all\"].split(\",\"))\n",
    "    relation_pairs = set()\n",
    "    for word_premise in important_premise:\n",
    "        related_words = simple_relation_functions[relation](word_premise)\n",
    "        for present_related_word in related_words.intersection(important_hypothesis):\n",
    "            relation_pairs.add((word_premise, present_related_word))\n",
    "    return { relation: len(relation_pairs) }\n",
    "\n",
    "def are_co_hyponym(word_1: str, word_2: str) -> bool:\n",
    "    common_hypernyms = get_hypernyms(word_1).intersection(get_hypernyms(word_2))\n",
    "    return len(common_hypernyms) > 0\n",
    "\n",
    "def add_co_hyponym_column(record: dict) -> dict:\n",
    "    important_premise = set(record[\"highlighted_premise_all\"].split(\",\"))\n",
    "    important_hypothesis = set(record[\"highlighted_hypothesis_all\"].split(\",\"))\n",
    "    relation_pairs = set()\n",
    "    for word_premise in important_premise:\n",
    "        for word_hypothesis in important_hypothesis:\n",
    "            if are_co_hyponym(word_premise, word_hypothesis):\n",
    "                relation_pairs.add((word_premise, word_hypothesis))\n",
    "    return { \"co_hyponym\": len(relation_pairs) }\n",
    "\n",
    "splits = [\"train\", \"test\", \"validation\"]\n",
    "for split in splits:\n",
    "    for key in simple_relation_functions.keys():\n",
    "        print(f\"Adding {key} column to {split} split...\")\n",
    "        esnli[split] = esnli[split].map(add_simple_relation_column, fn_kwargs={ \"relation\": key }, num_proc=8)\n",
    "    print(f\"Adding co-hyponym column to {split} split...\")\n",
    "    esnli[split] = esnli[split].map(add_co_hyponym_column, num_proc=8)\n",
    "    esnli[split].to_csv(f\"../datasets/esnli_{split}_phenomena.csv\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lit",
   "language": "python",
   "name": "lit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cfcc2acf294dde4d86524a90ff670499346cddafd0bf29378570443a1635a34f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
